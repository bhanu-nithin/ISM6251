{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b7fe023",
   "metadata": {},
   "source": [
    "## Assignment 1.b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b62d5e",
   "metadata": {},
   "source": [
    "## Model fitting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70a53a4",
   "metadata": {},
   "source": [
    "### importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5259f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "#!pip install imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from __future__ import print_function\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf57c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\Downloads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd7c29",
   "metadata": {},
   "source": [
    "## Loading the preprocessed data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbea0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"default_train_df.csv\")\n",
    "test_df=pd.read_csv(\"default_test_df.csv\")\n",
    "X_train=pd.read_csv(\"default_train_X.csv\")\n",
    "X_test=pd.read_csv(\"default_test_X.csv\")\n",
    "y_train=pd.read_csv(\"default_train_y.csv\")\n",
    "y_test=pd.read_csv(\"default_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "562d4708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEFAULT PAYMENT NEXT MONTH\n",
       "0                             16364\n",
       "1                              4636\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1c435",
   "metadata": {},
   "source": [
    "*** There is a huge imbalance in the trained data so we need to perform a data imbalance techniqu in order to encounter the biased results ***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6e305c",
   "metadata": {},
   "source": [
    "## Data imbalancing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb04e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'DEFAULT PAYMENT NEXT MONTH': 1})\n"
     ]
    }
   ],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bf69c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEFAULT PAYMENT NEXT MONTH\n",
       "0                             4636\n",
       "1                             4636\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfb2a77",
   "metadata": {},
   "source": [
    "## Standardizing the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df673530",
   "metadata": {},
   "source": [
    "Here we will be standardizing the variables of each attribute in order to reduce the differences among them so that we will be able to predict the scores accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6901e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Transform the predictors of training and test sets\n",
    "X_train = scaler.transform(X_train) \n",
    " \n",
    "\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce9e6d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1594649 ,  1.59086926,  0.83370498, ...,  1.48177835,\n",
       "        -0.22219406, -0.22989422],\n",
       "       [ 0.87887396, -0.50438208,  0.83370498, ..., -0.10248862,\n",
       "         0.01905733, -0.22452629],\n",
       "       [-0.24172336, -0.42379549, -1.19946507, ..., -0.29645833,\n",
       "        -0.07275223, -0.28920017],\n",
       "       ...,\n",
       "       [ 0.50824613,  0.22089723,  0.83370498, ..., -0.29645833,\n",
       "        -0.28920834, -0.28920017],\n",
       "       [-1.40542505, -0.42379549, -1.19946507, ..., -0.29645833,\n",
       "        -0.24424176, -0.245804  ],\n",
       "       [ 0.25914704,  0.14031064,  0.83370498, ..., -0.22405455,\n",
       "        -0.28920834,  2.08297309]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be534acb",
   "metadata": {},
   "source": [
    "### What is the best evaluating matrix????"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cd698",
   "metadata": {},
   "source": [
    "Our aim for this analysis is to predict accurately the default payments of a transaction. So we will be dealing with both the True Positives and False Negitives of the problem because, True positives(TP) gives number of times the model correctly predicts a default payment whereas False Negitives(FN) gives the number of times the model incorrectly predicts a non-default payment when the actual payment is a default. False negitives are also as important as True Negitives in order to define this model s accurate one.\n",
    "\n",
    "Recall is a predictive metric that deals with both true positives and false negatives. The proportion of true positives among all actual positive observations is measured by recall. It indicates how well the model can identify positive cases.\n",
    "\n",
    "Formula :\n",
    "Recall = True Positives / (True Positives + False Negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6ccf6b",
   "metadata": {},
   "source": [
    "## Modelling the data with various modelling techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7dd3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754eb6e8",
   "metadata": {},
   "source": [
    "### Decision Trees\n",
    "### Using Random search and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ef4c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "The best recall score is 0.6048203178749908\n",
      "... with parameters: {'min_samples_split': 45, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.001, 'max_leaf_nodes': 89, 'max_depth': 23, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.001, 0.005),\n",
    "    'max_leaf_nodes': np.arange(5, 100), \n",
    "    'max_depth': np.arange(1,25), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_DTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc29d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1280 candidates, totalling 6400 fits\n",
      "The best recall score is 0.5759336755570434\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 21, 'max_leaf_nodes': 87, 'min_impurity_decrease': 0.00095, 'min_samples_leaf': 3, 'min_samples_split': 43}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-2,min_samples_split+2),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-2,min_samples_leaf+2),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-2,max_leaf_nodes+2), \n",
    "    'max_depth': np.arange(max_depth-2,max_depth+2), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_DTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b369b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.7717778 Precision=0.4876147 Recall=0.5315000 F1=0.5086124\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_Dtree= {TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3be63b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "203a84e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.771778</td>\n",
       "      <td>0.487615</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>0.508612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model  Accuracy  Precision  Recall        F1\n",
       "0  Decision Tree  0.771778   0.487615  0.5315  0.508612"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d23c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fecfecb",
   "metadata": {},
   "source": [
    "###  Logistic Regression\n",
    "### using Random search and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12b6e9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "132 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "42 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.6251054  0.62036044        nan        nan 0.62402707        nan\n",
      " 0.62510554        nan        nan        nan        nan        nan\n",
      "        nan 0.6251054  0.62424282 0.62057619 0.62575251 0.6251054\n",
      " 0.55715972        nan 0.62532115 0.62532115 0.62532115 0.62812436\n",
      " 0.62532115 0.62812436 0.6190665         nan 0.62726164        nan\n",
      " 0.61885089 0.62510554 0.62036044 0.62812436        nan 0.62402707\n",
      " 0.62532115 0.62575251 0.62575251        nan        nan 0.62532115\n",
      " 0.62510554 0.6251054  0.62532115        nan        nan 0.62532115\n",
      " 0.62575251 0.62532115        nan        nan        nan        nan\n",
      " 0.62402707        nan 0.62532115        nan        nan        nan\n",
      "        nan 0.5718247         nan 0.6251054  0.57160895 0.62812436\n",
      "        nan 0.62532115        nan 0.62532115        nan 0.62532115\n",
      "        nan        nan 0.6251054         nan 0.62532115 0.6251054\n",
      " 0.62532115 0.62812436 0.62532115        nan        nan        nan\n",
      " 0.62532115        nan        nan 0.61885089 0.62575251        nan\n",
      " 0.6251054         nan 0.62575251 0.6251054         nan 0.62532115\n",
      "        nan 0.62575251        nan        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.628124358926052\n",
      "... with parameters: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 390, 'C': 0.01}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':[0.01,0.1,1,2,10], # C is the regulization strength\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(250,500)\n",
    "                  \n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator =log_reg, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_log_reg = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad7ba9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 600 candidates, totalling 1800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.628124358926052\n",
      "... with parameters: {'C': 0.01, 'max_iter': 90, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength,min_regulization_strength+0.5), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-300,min_iter+300)\n",
    "}\n",
    "\n",
    "log_reg =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = log_reg, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,error_score='raise' # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_log_reg = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b304e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.7022222 Precision=0.3914432 Recall=0.6130000 F1=0.4777864\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_logistic= {TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "680ac0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic regression using random search & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88fb5d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.771778</td>\n",
       "      <td>0.487615</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>0.508612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression using random search &amp; grid...</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.391443</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.477786</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  Accuracy  Precision  \\\n",
       "0                                      Decision Tree  0.771778   0.487615   \n",
       "0  logistic regression using random search & grid...  0.702222   0.391443   \n",
       "\n",
       "   Recall        F1  \n",
       "0  0.5315  0.508612  \n",
       "0  0.6130  0.477786  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048274ea",
   "metadata": {},
   "source": [
    "### SVM using random search and grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d045a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':np.arange(0.1,50,10), \n",
    "               'kernel':['linear', 'rbf','poly'],\n",
    "              'gamma':['scale','auto'],\n",
    "              'degree':np.arange(1,10), \n",
    "              'coef0':np.arange(1,10)\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svc, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestsvc = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc06bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_kernel = rand_search.best_params_['kernel']\n",
    "best_gamma = rand_search.best_params_['gamma']\n",
    "min_regulization=rand_search.best_params_['C']\n",
    "best_degree = rand_search.best_params_['degree']\n",
    "best_coef0=rand_search.best_params_['coef0']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization-3,min_regulization+3), \n",
    "               'kernel':[best_kernel],\n",
    "              'gamma':[best_gamma],\n",
    "              'degree': np.arange(best_degree-1,best_degree+1),\n",
    "            'coef0': np.arange(best_coef0-3,best_coef0+3)\n",
    "}\n",
    "\n",
    "svm_grid =  SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99658055",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "F1_svm=2*TP/(2*TP+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92570f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm \", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5f2e73",
   "metadata": {},
   "source": [
    "#### We can observe that the recall score of decision tree and logistic regression using random search and grid search is 0.60 and 0.62 respectively which is almost equal. Comming to Support Vector Machines we are unable to get the result because of (incompatability of the system). So in this business problem we are mostly focussed on true positives(TP)(gives number of times the model correctly predicts a default payment) and False negatives(FN)(gives the number of times the model incorrectly predicts a non-default payment when the actual payment is a default). So when compared the best AI model developed to detect the default payments of both TP and FN is logisitic regression model. This model can detect the solution with less FN and more TP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baefee3",
   "metadata": {},
   "source": [
    "## MLP Classifier using SKlearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "243389d5",
   "metadata": {
    "id": "5WfGTWb3hYd-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 40 s\n",
      "Wall time: 13.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train,np.ravel( y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a421f866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 16.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "754ac0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79      7000\n",
      "           1       0.38      0.55      0.45      2000\n",
      "\n",
      "    accuracy                           0.70      9000\n",
      "   macro avg       0.62      0.65      0.62      9000\n",
      "weighted avg       0.75      0.70      0.72      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa5e2954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'adam', 'max_iter': 1000, 'learning_rate_init': 0.5, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (128, 64), 'early_stopping': True, 'alpha': 0.001, 'activation': 'relu'}\n",
      "CPU times: total: 3.53 s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (64,), (128,),(128,64), (64,128), (64,128,196), (196,128,64)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .001, .005, .01, .05],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'early_stopping':[True],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b0a558f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88      7000\n",
      "           1       0.00      0.00      0.00      2000\n",
      "\n",
      "    accuracy                           0.78      9000\n",
      "   macro avg       0.39      0.50      0.44      9000\n",
      "weighted avg       0.60      0.78      0.68      9000\n",
      "\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 49.8 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819af11d",
   "metadata": {},
   "source": [
    "## With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d015048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1098: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0, 'hidden_layer_sizes': (64,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.2, 'max_iter': 1000, 'solver': 'sgd'}\n",
      "CPU times: total: 27.9 s\n",
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (64,), (128,),(128,64)],\n",
    "    'activation': ['logistic', 'relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [0,.5 ],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.1,0.2,0.5],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54a95689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.70      0.78      7000\n",
      "           1       0.38      0.64      0.47      2000\n",
      "\n",
      "    accuracy                           0.69      9000\n",
      "   macro avg       0.62      0.67      0.62      9000\n",
      "weighted avg       0.76      0.69      0.71      9000\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 32.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1dd4320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.6853333 Precision=0.3772137 Recall=0.6390000 F1=0.4743875\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "F1_lr=2*TP/(2*TP+FP+FN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecb22c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"neural network using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d59e5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.771778</td>\n",
       "      <td>0.487615</td>\n",
       "      <td>0.5315</td>\n",
       "      <td>0.508612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression using random search &amp; grid...</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.391443</td>\n",
       "      <td>0.6130</td>\n",
       "      <td>0.477786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural network using random &amp; grid search</td>\n",
       "      <td>0.685333</td>\n",
       "      <td>0.377214</td>\n",
       "      <td>0.6390</td>\n",
       "      <td>0.474388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  Accuracy  Precision  \\\n",
       "0                                      Decision Tree  0.771778   0.487615   \n",
       "0  logistic regression using random search & grid...  0.702222   0.391443   \n",
       "0          neural network using random & grid search  0.685333   0.377214   \n",
       "\n",
       "   Recall        F1  \n",
       "0  0.5315  0.508612  \n",
       "0  0.6130  0.477786  \n",
       "0  0.6390  0.474388  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a64b13",
   "metadata": {},
   "source": [
    " #### We've used random and grid search to implement the SKlearn MLP classifier, and there are important parameters that go into determining the data's confusion matrix. We have provided the hidden layer size values as multiples of 4, as well as the number of data entries as multiples of 4. Max_iter is specified as 1000, which should be practical given the compatibility of the system. The best parameters from the above result were utilized to do grid search after performing random search in order to obtain the mlp classifier predictive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be0f524",
   "metadata": {},
   "source": [
    "### Keras Sequential Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d72dd175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=24)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        ann.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        ann.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    #the out is either 0 or 1 which is single numeric value, like a regression task so the tensor shape is (None,1)\n",
    "    \n",
    "    ann.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22f73b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout = 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4229c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c017ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 970us/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 2ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "93/93 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 3ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 1ms/step\n",
      "31/31 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='f1', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4b6bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2072c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.005,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (90,),\n",
       " 'model__dropout': 0,\n",
       " 'epochs': 10,\n",
       " 'batch_size': 20}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95b4137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cac680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 1s 2ms/step\n",
      "best score 0.7553333333333333\n",
      "min loss 0.5560616254806519\n",
      "CPU times: total: 4.53 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"best score {best_model.score(X_test, y_test)}\")\n",
    "print(f\"min loss {min(best_model.history_['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81ce850d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [0.6037212014198303,\n",
       "              0.5836703181266785,\n",
       "              0.574445903301239,\n",
       "              0.5693883299827576,\n",
       "              0.5662752389907837,\n",
       "              0.5630691051483154,\n",
       "              0.5613280534744263,\n",
       "              0.5591203570365906,\n",
       "              0.5575400590896606,\n",
       "              0.5560616254806519],\n",
       "             'accuracy': [0.6761216521263123,\n",
       "              0.6976919770240784,\n",
       "              0.7068593502044678,\n",
       "              0.7073985934257507,\n",
       "              0.7160267233848572,\n",
       "              0.7148403525352478,\n",
       "              0.7148403525352478,\n",
       "              0.7185073494911194,\n",
       "              0.7190465927124023,\n",
       "              0.7169973850250244]})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1f373ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a9169ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 1s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8753    0.7993    0.8356      7000\n",
      "           1     0.4613    0.6015    0.5221      2000\n",
      "\n",
      "    accuracy                         0.7553      9000\n",
      "   macro avg     0.6683    0.7004    0.6789      9000\n",
      "weighted avg     0.7833    0.7553    0.7659      9000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fd317cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a733a4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 1s 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84      7000\n",
      "           1       0.46      0.60      0.52      2000\n",
      "\n",
      "    accuracy                           0.76      9000\n",
      "   macro avg       0.67      0.70      0.68      9000\n",
      "weighted avg       0.78      0.76      0.77      9000\n",
      "\n",
      "CPU times: total: 3.75 s\n",
      "Wall time: 968 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a029babb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.7553333 Precision=0.4612730 Recall=0.6015000 F1=0.5221354\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "F1_lr=2*TP/(2*TP+FP+FN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90f75a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"using keras\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b559009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>using keras</td>\n",
       "      <td>0.755333</td>\n",
       "      <td>0.461273</td>\n",
       "      <td>0.6015</td>\n",
       "      <td>0.522135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         model  Accuracy  Precision  Recall        F1\n",
       "0  using keras  0.755333   0.461273  0.6015  0.522135"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be35723",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6876ff6",
   "metadata": {},
   "source": [
    "Models performed in this assignment :\n",
    "\n",
    "    Decision Tree using random search and grid search     \n",
    "    Logistic regression using random search and grid search\n",
    "    SVM using random search and grid search\n",
    "    SKlearn MLP classifier using random search and grid search\n",
    "    Keras Sequential Search \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dd3ffb",
   "metadata": {},
   "source": [
    " Confusion Matrix Display:\n",
    "    From the keras model we can interpret the confusion matrix details as number of TP are 1203, number of FN  are -5595. \n",
    "    as per the business problem here we will be concentrating on TP and FN. total of 1203 predictions are donw where the model       correctly predicts a default payment whereas the total of 5595 predictions were done where the  model incorrectly predicts a     non-default payment when the actual payment is a default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df3843",
   "metadata": {},
   "source": [
    "From all the predicted models we will be concentrating on the recall score of each model as it depends on both TP and FN. \n",
    "The recall scores obtained are \n",
    "\n",
    "Note : SVM is The model is taking a lot longer than anticipated to run, tried a number of tests and experiments to try to figure out what's causing this problem, but I've been unsuccessful so far\n",
    ".\n",
    "decision tree :  0.53\n",
    "Logistic regression : 0.61\n",
    "MLP classifier : 0.63\n",
    "Keras sequencial search : 0.60\n",
    "\n",
    "Here by we can conclude that the best predictive model is MLP classifier model.\n",
    "Comparing the MLP classifier with the past models used such as decision tree model , decision tree models are more prone to over fitting but incase of MLP classifier we can overcome the issue by regularization techniques. \n",
    "MLP classifier can model more complex linear relationships when compared to the past models (decision trees and logistic regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed952607",
   "metadata": {},
   "source": [
    "As per my research while comparing both mlp classifier and logisitic regression we can observe that mlp classfier can peform much more better when dealing with complex relationships or high dimensional data. however, when dealing with simplier data logisitic is the good model to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69457193",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
