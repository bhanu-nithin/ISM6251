{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f71b69d6",
   "metadata": {},
   "source": [
    "# Week 4 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ea72e",
   "metadata": {},
   "source": [
    "\n",
    "## Manne Bhanu Nithin Yadav "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d7ac3a",
   "metadata": {},
   "source": [
    "### 1.0 Import required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f634b3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e5d52a",
   "metadata": {},
   "source": [
    "### 2.0 Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f16eb6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/Nithin Yadav/Desktop/DSP/UniversalBank (2).csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891f4c37",
   "metadata": {},
   "source": [
    "### Summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "892775a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "#.info gives us the null character count and the data type of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417308b",
   "metadata": {},
   "source": [
    "### Checking missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70edfbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the missing values by summing the total na's for each variable\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa3aa0f",
   "metadata": {},
   "source": [
    "## No missing valus found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a85debb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4698\n",
       "1     302\n",
       "Name: CD Account, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CD Account'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0852d63",
   "metadata": {},
   "source": [
    "## Data imbalancing found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be455ab1",
   "metadata": {},
   "source": [
    "## 3.0 Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889a0332",
   "metadata": {},
   "source": [
    "We dont have any categorical variables and we dont have any missing values so we need not do any covertion into numeric or we need not impute values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd96e43",
   "metadata": {},
   "source": [
    "### Dropping unessasary columns\n",
    "\n",
    "Dropping unuseful data can help us to process the model quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f64bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.drop(columns=['ID', 'ZIP Code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf77ce",
   "metadata": {},
   "source": [
    "### Splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5037bcd4",
   "metadata": {},
   "source": [
    "Lets split the data into training data and the test data with the ratio of 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54713086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=1)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'CD Account'\n",
    "predictors = list(df.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082acbe",
   "metadata": {},
   "source": [
    "## Standardizing the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecfa0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "# Transform the predictors of training and test sets\n",
    "X_train = scaler.transform(train_df[predictors]) \n",
    "y_train = train_df[target] \n",
    "\n",
    "X_test = scaler.transform(test_df[predictors])\n",
    "y_test = test_df[target] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2568de",
   "metadata": {},
   "source": [
    "##  Modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae91863",
   "metadata": {},
   "source": [
    "###  Logistic Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7956fbb7",
   "metadata": {},
   "source": [
    "###  Logistic Regression using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152b371c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "210 fits failed out of a total of 500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "55 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 78, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "65 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1101, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.25095137 0.66627907 0.                nan        nan 0.66627907\n",
      " 0.         0.66627907        nan 0.66627907 0.66627907        nan\n",
      " 0.66627907 0.31469345        nan        nan 0.31469345        nan\n",
      "        nan 0.66627907 0.                nan 0.05940803 0.\n",
      "        nan 0.         0.66627907        nan 0.66627907        nan\n",
      "        nan        nan 0.66627907 0.66627907 0.05940803 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.66627907        nan 0.66627907\n",
      " 0.                nan 0.66627907        nan 0.31469345        nan\n",
      " 0.66627907        nan        nan        nan 0.66627907 0.\n",
      " 0.66627907 0.66627907        nan 0.66627907        nan        nan\n",
      " 0.25095137 0.66627907 0.         0.66627907 0.66627907        nan\n",
      "        nan 0.66627907        nan 0.25095137        nan 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907        nan        nan 0.66627907\n",
      " 0.66627907 0.05940803        nan        nan 0.66627907        nan\n",
      " 0.67082452 0.25095137        nan        nan 0.05940803 0.67082452\n",
      "        nan 0.25095137 0.66627907        nan        nan        nan\n",
      " 0.66627907        nan 0.                nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "parameters = {'C':[0.001,0.01,0.1,1,5], # C is the regulization strength\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(250,500)\n",
    "                  \n",
    "}\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator =log_reg, param_distributions=parameters, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  # n_jobs=-1 will utilize all available CPUs \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "bestlogestic = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d60d23b",
   "metadata": {},
   "source": [
    "## using paramters from randomsearch we are going to use them in gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ba3b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "parameters = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-0.03,min_regulization_strength+0.03), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-200,min_iter+200)\n",
    "}\n",
    "\n",
    "log_grid =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = log_grid, param_grid=parameters, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 # n_jobs=-1 will utilize all available CPUs \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestlgr = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71747d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_lr={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7ce7463",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29bbcb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "455612e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d424098",
   "metadata": {},
   "source": [
    " ## Fit and test a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfdfb606",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none', max_iter=900)\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "016d73c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix_1 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_1[1][1]\n",
    "TN = c_matrix_1[0][0]\n",
    "FP = c_matrix_1[0][1]\n",
    "FN = c_matrix_1[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c551023",
   "metadata": {},
   "source": [
    " ## liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "864bb35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_liblin_model = LogisticRegression(solver='liblinear').fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c12475ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_liblin_model.predict(X_test)\n",
    "c_matrix_2 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_2[1][1]\n",
    "TN = c_matrix_2[0][0]\n",
    "FP = c_matrix_2[0][1]\n",
    "FN = c_matrix_2[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"liblinear logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f79da",
   "metadata": {},
   "source": [
    " ## L1 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b00094",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L1_model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "_ = log_reg_L1_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e68d5313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_L1_model.predict(X_test)\n",
    "c_matrix_4 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_4[1][1]\n",
    "TN = c_matrix_4[0][0]\n",
    "FP = c_matrix_4[0][1]\n",
    "FN = c_matrix_4[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L1 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390acdfb",
   "metadata": {},
   "source": [
    "## L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ce567c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_L2_model = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "_ = log_reg_L2_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7da11d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds_3 = log_reg_L2_model.predict(X_test)\n",
    "c_matrix_3 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_3[1][1]\n",
    "TN = c_matrix_3[0][0]\n",
    "FP = c_matrix_3[0][1]\n",
    "FN = c_matrix_3[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"L2 logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3872a770",
   "metadata": {},
   "source": [
    "## Elastic Net Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6217c637",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_elastic_model = LogisticRegression(solver='saga', penalty='elasticnet', l1_ratio=0.5, max_iter=1000)\n",
    "_ = log_reg_elastic_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b02862c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>liblinear logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L1 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L2 logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elestic logistic</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.60241</td>\n",
       "      <td>0.75188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision   Recall       F1\n",
       "0  logistic using random & grid search     0.978        1.0  0.60241  0.75188\n",
       "0                     default logistic     0.978        1.0  0.60241  0.75188\n",
       "0                   liblinear logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L1 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                          L2 logistic     0.978        1.0  0.60241  0.75188\n",
       "0                     Elestic logistic     0.978        1.0  0.60241  0.75188"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = log_reg_elastic_model.predict(X_test)\n",
    "c_matrix_5 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_5[1][1]\n",
    "TN = c_matrix_5[0][0]\n",
    "FP = c_matrix_5[0][1]\n",
    "FN = c_matrix_5[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Elestic logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b822824",
   "metadata": {},
   "source": [
    "###  Model the data using the SVM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d65cc",
   "metadata": {},
   "source": [
    "###  SVM using RandomSearch and Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "baa70834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 500 candidates, totalling 1500 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {'C':np.arange(0.1,100,10),  \n",
    "               'kernel':['linear', 'rbf','poly'],\n",
    "              'gamma':['scale','auto'],\n",
    "              'degree':np.arange(1,10),\n",
    "              'coef0':np.arange(1,10) \n",
    "                  \n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator =svc, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1  \n",
    "                                )\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "bestsvc = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f421eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 3\n",
    "best_kernel = rand_search.best_params_['kernel']\n",
    "best_gamma = rand_search.best_params_['gamma']\n",
    "min_regulization=rand_search.best_params_['C']\n",
    "best_degree = rand_search.best_params_['degree']\n",
    "best_coef0=rand_search.best_params_['coef0']\n",
    "\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization-3,min_regulization+3), \n",
    "               'kernel':[best_kernel],\n",
    "              'gamma':[best_gamma],\n",
    "              'degree': np.arange(best_degree-1,best_degree+1),\n",
    "            'coef0': np.arange(best_coef0-3,best_coef0+3)\n",
    "}\n",
    "\n",
    "svm_grid =  SVC()\n",
    "grid_search = GridSearchCV(estimator = svm_grid, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1 \n",
    "                )\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_svm = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "363b46e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9546667 Precision=0.5824176 Recall=0.6385542 F1=0.6091954\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_svm={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1be1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_svm = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ecd9856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"svm using Random & Grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65f59def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0  svm using Random & Grid search  0.954667   0.582418  0.638554  0.609195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b167a",
   "metadata": {},
   "source": [
    "###  Fit a SVM classification model using linear kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a2c42ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\")\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a822e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0  svm using Random & Grid search  0.954667   0.582418  0.638554  0.609195\n",
       "0                      linear svm  0.978000   1.000000  0.602410  0.751880"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "c_matrix_6 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_6[1][1]\n",
    "TN = c_matrix_6[0][0]\n",
    "FP = c_matrix_6[0][1]\n",
    "FN = c_matrix_6[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"linear svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a45d3",
   "metadata": {},
   "source": [
    "###  Fit a SVM classification model using rbf kernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "814ad532",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale')\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7beead2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0  svm using Random & Grid search  0.954667   0.582418  0.638554  0.609195\n",
       "0                      linear svm  0.978000   1.000000  0.602410  0.751880\n",
       "0                         rbf svm  0.974667   0.909091  0.602410  0.724638"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "c_matrix_7 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_7[1][1]\n",
    "TN = c_matrix_7[0][0]\n",
    "FP = c_matrix_7[0][1]\n",
    "FN = c_matrix_7[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"rbf svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2859ef55",
   "metadata": {},
   "source": [
    "###  Fit a SVM classification model using polynomial kernal¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c18b19bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "52eb36bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0  svm using Random & Grid search  0.954667   0.582418  0.638554  0.609195\n",
       "0                      linear svm  0.978000   1.000000  0.602410  0.751880\n",
       "0                         rbf svm  0.974667   0.909091  0.602410  0.724638\n",
       "0                        poly svm  0.970000   0.806452  0.602410  0.689655"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "c_matrix_8 = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix_8[1][1]\n",
    "TN = c_matrix_8[0][0]\n",
    "FP = c_matrix_8[0][1]\n",
    "FN = c_matrix_8[1][0]\n",
    "performance_svm = pd.concat([performance_svm, pd.DataFrame({'model':\"poly svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a4a702",
   "metadata": {},
   "source": [
    "### Summary of the SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c54d7a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.954667</td>\n",
       "      <td>0.582418</td>\n",
       "      <td>0.638554</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                      linear svm  0.978000   1.000000  0.602410  0.751880\n",
       "0                         rbf svm  0.974667   0.909091  0.602410  0.724638\n",
       "0                        poly svm  0.970000   0.806452  0.602410  0.689655\n",
       "0  svm using Random & Grid search  0.954667   0.582418  0.638554  0.609195"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_svm.sort_values(by=['Recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4221c4a",
   "metadata": {},
   "source": [
    "###  Model the data using the Decision Trees using RandomSearchCV combined with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c002220",
   "metadata": {},
   "source": [
    "Using the Random search to get the best parameters from the range which can be later used in the Grid search to get more refined results with less overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "749dfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "85 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "85 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.29682875 0.63890063 0.59830867 0.62536998 0.66649049 0.63890063\n",
      " 0.56162791 0.56162791 0.56183932 0.51638478 0.64799154 0.63890063\n",
      " 0.59830867 0.63890063 0.         0.59830867 0.56162791 0.64799154\n",
      " 0.59830867 0.59830867 0.49788584 0.64799154 0.59830867 0.59830867\n",
      " 0.29682875 0.51638478 0.53890063 0.29682875 0.64799154 0.59830867\n",
      " 0.65718816 0.63890063 0.59830867 0.59830867 0.66649049 0.29682875\n",
      " 0.51638478 0.51638478 0.59830867 0.63890063 0.59830867 0.29682875\n",
      " 0.66649049 0.63890063 0.29682875 0.59830867 0.59830867 0.52061311\n",
      " 0.59830867 0.59830867 0.6435518  0.59830867 0.66649049 0.59830867\n",
      " 0.63890063 0.29682875 0.59344609 0.66649049 0.66627907 0.51638478\n",
      " 0.59830867 0.51638478 0.29682875 0.59344609 0.62103594 0.59830867\n",
      " 0.59830867 0.56162791 0.64799154 0.54334038 0.64799154 0.59830867\n",
      " 0.59830867 0.59830867 0.57547569 0.63890063 0.65708245 0.\n",
      " 0.         0.64799154 0.59830867 0.65708245 0.29682875 0.59830867\n",
      " 0.         0.59830867 0.29682875 0.57547569 0.63890063 0.51638478\n",
      " 0.59830867 0.67082452 0.63890063        nan 0.66627907 0.51638478\n",
      " 0.59344609 0.58921776 0.59830867 0.59830867        nan 0.67082452\n",
      " 0.53890063 0.63890063 0.63890063 0.29682875 0.         0.31955603\n",
      " 0.55729387 0.63890063 0.29682875 0.59830867 0.59830867 0.59830867\n",
      " 0.65708245 0.59830867 0.53890063 0.29682875 0.59830867 0.62103594\n",
      " 0.56183932 0.63890063 0.51638478 0.63890063 0.         0.\n",
      " 0.59830867 0.         0.59830867 0.51638478 0.52526427 0.59830867\n",
      " 0.29682875 0.59830867 0.29682875 0.63890063 0.         0.51638478\n",
      " 0.29682875 0.         0.49788584 0.59830867 0.59830867 0.63890063\n",
      " 0.63890063 0.51638478 0.59344609 0.59830867 0.59830867 0.59830867\n",
      " 0.64809725 0.63890063 0.59830867 0.59830867 0.51638478 0.65264271\n",
      " 0.59376321 0.59830867 0.55729387 0.59830867 0.52061311 0.52526427\n",
      " 0.63890063 0.63890063 0.                nan 0.59830867 0.59830867\n",
      " 0.29682875 0.49788584 0.59830867 0.29682875 0.         0.\n",
      " 0.52526427 0.59344609 0.59344609 0.57071882 0.59830867 0.59344609\n",
      " 0.48879493 0.59830867 0.55729387 0.51638478        nan 0.\n",
      " 0.56162791 0.70295983        nan 0.59376321 0.58921776 0.\n",
      " 0.54799154 0.56162791 0.63890063 0.         0.67547569 0.\n",
      " 0.63900634 0.59830867 0.63890063 0.59830867        nan        nan\n",
      " 0.63890063 0.49788584 0.59830867 0.59830867 0.         0.6435518\n",
      " 0.51638478 0.59376321 0.29682875 0.59830867 0.51638478 0.64799154\n",
      " 0.63890063 0.64799154 0.59830867 0.63890063 0.         0.59830867\n",
      " 0.55729387 0.6435518  0.66649049 0.29682875 0.29682875 0.29682875\n",
      " 0.48879493 0.65718816 0.64799154 0.51638478 0.55274841 0.66649049\n",
      " 0.29682875 0.59830867 0.29682875 0.59830867 0.29682875 0.59830867\n",
      " 0.50697674 0.59830867 0.         0.59344609 0.59830867 0.63890063\n",
      " 0.59830867 0.56162791 0.59830867 0.59344609        nan 0.\n",
      " 0.53890063 0.                nan 0.54799154 0.29682875 0.59830867\n",
      " 0.59830867 0.59830867 0.65708245 0.63890063 0.59830867 0.56162791\n",
      " 0.54799154 0.49788584 0.29682875 0.56183932 0.51638478 0.59830867\n",
      " 0.                nan 0.59830867 0.54799154 0.59830867 0.54799154\n",
      " 0.59830867 0.63890063 0.50697674 0.56162791 0.50697674        nan\n",
      " 0.64799154 0.55729387        nan 0.56617336 0.63890063 0.59830867\n",
      " 0.51638478 0.56162791 0.51638478 0.59830867 0.59830867 0.58921776\n",
      " 0.59376321 0.59830867 0.56162791 0.63890063 0.59830867 0.52526427\n",
      " 0.29682875 0.63890063 0.52526427 0.59830867 0.64799154 0.50697674\n",
      " 0.29682875 0.64799154 0.63890063 0.29682875 0.29682875 0.56162791\n",
      " 0.51638478 0.59830867 0.59830867 0.57547569 0.66627907 0.50697674\n",
      " 0.65718816 0.59344609 0.59830867 0.29682875 0.55729387 0.56162791\n",
      " 0.59830867 0.63890063        nan 0.65708245 0.4602537  0.59344609\n",
      " 0.59830867 0.59830867 0.29682875        nan 0.59830867 0.65718816\n",
      " 0.59830867 0.54799154 0.59830867 0.59830867 0.63890063 0.54799154\n",
      " 0.64799154 0.59830867 0.56183932 0.59830867 0.59830867 0.59830867\n",
      " 0.29682875 0.59344609 0.54799154 0.63890063 0.64799154 0.29682875\n",
      " 0.63890063 0.29682875 0.49788584 0.66649049 0.59830867 0.64799154\n",
      " 0.         0.37864693 0.64799154 0.59344609 0.50697674 0.59830867\n",
      " 0.56162791 0.54799154 0.59830867 0.48879493 0.59830867 0.64799154\n",
      " 0.59830867 0.63890063 0.59830867 0.63890063 0.29682875 0.64799154\n",
      " 0.55729387 0.64799154 0.59830867 0.59344609 0.56162791        nan\n",
      " 0.29682875 0.51638478 0.68023256 0.63890063 0.54799154 0.29682875\n",
      " 0.56183932 0.52526427 0.         0.63890063 0.59344609 0.59830867\n",
      " 0.51638478 0.65708245 0.59344609 0.29682875 0.55729387 0.59344609\n",
      " 0.58002114 0.29682875 0.65708245 0.56162791 0.63890063 0.59830867\n",
      " 0.59830867 0.59376321 0.5345666  0.62103594 0.63890063 0.59376321\n",
      " 0.59830867 0.59830867 0.59830867 0.59830867 0.66649049 0.56183932\n",
      " 0.59830867 0.55729387 0.56162791 0.59830867 0.56183932 0.63890063\n",
      " 0.59344609 0.64820296 0.59830867 0.64799154 0.29682875 0.58921776\n",
      " 0.59830867 0.59830867 0.59344609 0.63890063        nan 0.54799154\n",
      " 0.63890063 0.56162791 0.59830867 0.57547569 0.31955603 0.\n",
      " 0.49788584 0.65708245 0.53890063 0.56162791 0.52526427 0.6435518\n",
      " 0.29682875 0.51638478 0.29682875 0.67547569 0.59830867 0.59830867\n",
      " 0.59830867 0.59830867 0.59830867 0.56162791 0.         0.63890063\n",
      " 0.59344609 0.65718816 0.62103594 0.65708245 0.65708245 0.59830867\n",
      " 0.59344609 0.59830867 0.66649049 0.51638478 0.59830867 0.29682875\n",
      " 0.49788584 0.59344609 0.63890063 0.59830867 0.52526427 0.64809725\n",
      " 0.67082452 0.59830867 0.56183932 0.65708245 0.59830867 0.59830867\n",
      " 0.56183932 0.6435518  0.59830867 0.59830867 0.48879493 0.6435518\n",
      " 0.56162791 0.29682875 0.29682875 0.65718816 0.51638478 0.65718816\n",
      "        nan 0.56162791]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [0.33905844 0.64838961 0.59818182 0.66433117 0.65181169 0.64838961\n",
      " 0.6061039  0.6061039  0.54681169 0.49766883 0.65524675 0.63924675\n",
      " 0.59818182 0.64838961 0.         0.59818182 0.6061039  0.65524675\n",
      " 0.59818182 0.59818182 0.4931039  0.6632013  0.59818182 0.59818182\n",
      " 0.33905844 0.49766883 0.55924675 0.33905844 0.65981818 0.59818182\n",
      " 0.67120779 0.64838961 0.59818182 0.59818182 0.65181169 0.33905844\n",
      " 0.49766883 0.49766883 0.59818182 0.64838961 0.59818182 0.33905844\n",
      " 0.65181169 0.63924675 0.33905844 0.59818182 0.59818182 0.51253247\n",
      " 0.59818182 0.59818182 0.65408442 0.59818182 0.65181169 0.59818182\n",
      " 0.63924675 0.33905844 0.62438961 0.65181169 0.69064286 0.49424026\n",
      " 0.59818182 0.49538312 0.33905844 0.62438961 0.63695455 0.59818182\n",
      " 0.59818182 0.6061039  0.66206494 0.53538961 0.65524675 0.59818182\n",
      " 0.59818182 0.59818182 0.55595455 0.63924675 0.66324675 0.\n",
      " 0.         0.65638961 0.59818182 0.66324675 0.33905844 0.59818182\n",
      " 0.         0.59818182 0.33905844 0.55595455 0.63924675 0.49538312\n",
      " 0.59818182 0.66778571 0.63924675        nan 0.67692208 0.49766883\n",
      " 0.62438961 0.61866883 0.59818182 0.59818182        nan 0.67007143\n",
      " 0.55924675 0.63924675 0.64724675 0.33905844 0.         0.37783117\n",
      " 0.53538312 0.63924675 0.33905844 0.59818182 0.59818182 0.59818182\n",
      " 0.66324675 0.59818182 0.55924675 0.33905844 0.59818182 0.63695455\n",
      " 0.54566883 0.63924675 0.49766883 0.63924675 0.         0.\n",
      " 0.59818182 0.         0.59818182 0.49766883 0.53753247 0.59818182\n",
      " 0.33905844 0.59818182 0.33905844 0.63924675 0.         0.49424026\n",
      " 0.33905844 0.         0.4931039  0.59818182 0.59818182 0.63924675\n",
      " 0.64838961 0.49424026 0.62438961 0.59818182 0.59818182 0.59818182\n",
      " 0.70320779 0.63924675 0.59818182 0.59818182 0.49766883 0.67349351\n",
      " 0.58675325 0.59818182 0.53538312 0.59818182 0.51253247 0.53753247\n",
      " 0.63924675 0.63924675 0.                nan 0.59818182 0.59818182\n",
      " 0.33905844 0.4931039  0.59818182 0.33905844 0.         0.\n",
      " 0.53753247 0.62438961 0.62438961 0.58561688 0.59818182 0.62438961\n",
      " 0.48281818 0.59818182 0.53538312 0.49538312        nan 0.\n",
      " 0.6061039  0.80711039        nan 0.58675325 0.61866883 0.\n",
      " 0.58324675 0.6061039  0.63924675 0.         0.71577273 0.\n",
      " 0.66435065 0.59818182 0.64838961 0.59818182        nan        nan\n",
      " 0.63924675 0.4931039  0.59818182 0.59818182 0.         0.64609091\n",
      " 0.49538312 0.58675325 0.33905844 0.59818182 0.49766883 0.66206494\n",
      " 0.63924675 0.65524675 0.59818182 0.63924675 0.         0.59818182\n",
      " 0.53538312 0.64837662 0.65181169 0.33905844 0.33905844 0.33905844\n",
      " 0.48281818 0.72602597 0.65524675 0.49538312 0.53652597 0.65181169\n",
      " 0.33905844 0.59818182 0.33905844 0.59818182 0.33905844 0.59818182\n",
      " 0.50338961 0.59818182 0.         0.62438961 0.59818182 0.63924675\n",
      " 0.59818182 0.6061039  0.59818182 0.62438961        nan 0.\n",
      " 0.55924675 0.                nan 0.58324675 0.33905844 0.59818182\n",
      " 0.59818182 0.59818182 0.66896104 0.64838961 0.59818182 0.6061039\n",
      " 0.58324675 0.4931039  0.33905844 0.54681169 0.49538312 0.59818182\n",
      " 0.                nan 0.59818182 0.58324675 0.59818182 0.58324675\n",
      " 0.59818182 0.63924675 0.50338961 0.6061039  0.50338961        nan\n",
      " 0.65524675 0.53538312        nan 0.56847403 0.64838961 0.59818182\n",
      " 0.49766883 0.6061039  0.49424026 0.59818182 0.59818182 0.61866883\n",
      " 0.58675325 0.59818182 0.6061039  0.63924675 0.59818182 0.53753247\n",
      " 0.33905844 0.63924675 0.53753247 0.59818182 0.65638961 0.50338961\n",
      " 0.33905844 0.65638961 0.64838961 0.33905844 0.33905844 0.6061039\n",
      " 0.49766883 0.59818182 0.59818182 0.55595455 0.68948701 0.50338961\n",
      " 0.67464286 0.62438961 0.59818182 0.33905844 0.53538312 0.6061039\n",
      " 0.59818182 0.63924675        nan 0.66324675 0.46027273 0.62438961\n",
      " 0.59818182 0.59818182 0.33905844        nan 0.59818182 0.66892208\n",
      " 0.59818182 0.58324675 0.59818182 0.59818182 0.64838961 0.58324675\n",
      " 0.65524675 0.59818182 0.54566883 0.59818182 0.59818182 0.59818182\n",
      " 0.33905844 0.62438961 0.58324675 0.63924675 0.65524675 0.33905844\n",
      " 0.63924675 0.33905844 0.4931039  0.65181169 0.59818182 0.65524675\n",
      " 0.         0.42811688 0.65524675 0.62438961 0.50338961 0.59818182\n",
      " 0.6061039  0.58324675 0.59818182 0.4851039  0.59818182 0.65638961\n",
      " 0.59818182 0.63924675 0.59818182 0.63924675 0.33905844 0.65638961\n",
      " 0.53538312 0.6632013  0.59818182 0.62438961 0.6061039         nan\n",
      " 0.33905844 0.49766883 0.71574675 0.63924675 0.58324675 0.33905844\n",
      " 0.54566883 0.53753247 0.         0.63924675 0.62438961 0.59818182\n",
      " 0.49766883 0.66896104 0.62438961 0.33905844 0.53538312 0.62438961\n",
      " 0.56624026 0.33905844 0.66896104 0.6061039  0.63924675 0.59818182\n",
      " 0.59818182 0.58675325 0.51938312 0.63695455 0.64838961 0.58675325\n",
      " 0.59818182 0.59818182 0.59818182 0.59818182 0.65181169 0.54566883\n",
      " 0.59818182 0.53538312 0.6061039  0.59818182 0.54681169 0.64838961\n",
      " 0.62438961 0.65977922 0.59818182 0.65638961 0.33905844 0.61866883\n",
      " 0.59818182 0.59818182 0.62438961 0.63924675        nan 0.58324675\n",
      " 0.64838961 0.6061039  0.59818182 0.55595455 0.37783117 0.\n",
      " 0.4931039  0.66438961 0.55924675 0.6061039  0.53753247 0.65406494\n",
      " 0.33905844 0.49538312 0.33905844 0.71348701 0.59818182 0.59818182\n",
      " 0.59818182 0.59818182 0.59818182 0.6061039  0.         0.64838961\n",
      " 0.62438961 0.67006494 0.63695455 0.66324675 0.66324675 0.59818182\n",
      " 0.62438961 0.59818182 0.65181169 0.49538312 0.59818182 0.33905844\n",
      " 0.4931039  0.62438961 0.64838961 0.59818182 0.53753247 0.67692208\n",
      " 0.72262338 0.59818182 0.54681169 0.66324675 0.59818182 0.59818182\n",
      " 0.54681169 0.66321429 0.59818182 0.59818182 0.4851039  0.68835714\n",
      " 0.6061039  0.33905844 0.33905844 0.66892208 0.49766883 0.67006494\n",
      "        nan 0.6061039 ]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,50),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 50), \n",
    "    'max_depth': np.arange(1,15), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7b9d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 64 candidates, totalling 320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "160 fits failed out of a total of 320.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.69376321        nan 0.69386892        nan 0.69852008\n",
      "        nan 0.69841438        nan 0.69386892        nan 0.69841438\n",
      "        nan 0.69397463        nan 0.69841438        nan 0.69852008\n",
      "        nan 0.69841438        nan 0.69386892        nan 0.69841438\n",
      "        nan 0.70317125        nan 0.70295983        nan 0.69841438\n",
      "        nan 0.69841438        nan 0.69852008        nan 0.69841438\n",
      "        nan 0.6846723         nan 0.70295983        nan 0.69852008\n",
      "        nan 0.70295983        nan 0.68932347        nan 0.70295983\n",
      "        nan 0.68002114        nan 0.70750529        nan 0.68911205\n",
      "        nan 0.70295983        nan 0.68932347        nan 0.69841438\n",
      "        nan 0.68932347        nan 0.70295983]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Nithin Yadav\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the train scores are non-finite: [       nan 0.79794805        nan 0.78881169        nan 0.79908442\n",
      "        nan 0.78995455        nan 0.79794805        nan 0.78881169\n",
      "        nan 0.79337013        nan 0.78766883        nan 0.79908442\n",
      "        nan 0.78995455        nan 0.7990974         nan 0.78881169\n",
      "        nan 0.79908442        nan 0.78995455        nan 0.79794156\n",
      "        nan 0.78995455        nan 0.80594805        nan 0.80368182\n",
      "        nan 0.80594805        nan 0.80711039        nan 0.80594805\n",
      "        nan 0.80711039        nan 0.80366234        nan 0.80938312\n",
      "        nan 0.80937662        nan 0.80711039        nan 0.80937662\n",
      "        nan 0.80482468        nan 0.81051948        nan 0.80595455\n",
      "        nan 0.80937662        nan 0.81052597]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "min_samples_split = rand_search.best_params_['min_samples_split']\n",
    "min_samples_leaf = rand_search.best_params_['min_samples_leaf']\n",
    "min_impurity_decrease = rand_search.best_params_['min_impurity_decrease']\n",
    "max_leaf_nodes = rand_search.best_params_['max_leaf_nodes']\n",
    "max_depth = rand_search.best_params_['max_depth']\n",
    "criterion = rand_search.best_params_['criterion']\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(min_samples_split-1,min_samples_split+1),  \n",
    "    'min_samples_leaf': np.arange(min_samples_leaf-1,min_samples_leaf+1),\n",
    "    'min_impurity_decrease': np.arange(min_impurity_decrease-0.0001, min_impurity_decrease+0.0001, 0.00005),\n",
    "    'max_leaf_nodes': np.arange(max_leaf_nodes-1,max_leaf_nodes+1), \n",
    "    'max_depth': np.arange(max_depth-1,max_depth+1), \n",
    "    'criterion': [criterion]\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e06781f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9673333 Precision=0.7500000 Recall=0.6144578 F1=0.6754967\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25372b1a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e35b50c",
   "metadata": {},
   "source": [
    "The recall scores of all performed models are mentioned below :\n",
    "    Logistic regression:\n",
    "        Logistic regression using random search and grid search is 0.60241\n",
    "        Default logistic regression is    0.60241\n",
    "        liblinear logistic Regression is  0.60241\n",
    "        L1 logistic\tRegression   is       0.60241\n",
    "        L2 logistic\tRegression  is        0.60241\n",
    "        Elestic logistic Rgression is     0.60241\n",
    "        \n",
    "     SVM model \n",
    "       SVM using random and grid search cv is 0.638554\n",
    "        Linear SVM\t is   0.60241\n",
    "        RBF SVM      is    0.60241\n",
    "        Poly SVM    is  0.60241\n",
    "        \n",
    "    Decision tree model :\n",
    "        Decision tree using random and grid search is 0.6144578\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f0bec",
   "metadata": {},
   "source": [
    "from the results obtained we can observe that all the values of logistic regression are having the same values.\n",
    "after performing SVM model with random and grid search we are able to interpret the data as th recall score of svm model with random and grid search is more i.e 0.638554 which us more than the other svm models performed above\n",
    "The final model we have performed is the decision tree model using random and grid search where the recall score obtained was 0.6144578. After comparing all the values here by we can conclude that the SVM model using randomand grid search cv has the hughest recall value and can be considered as the best model according to the interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea49a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
